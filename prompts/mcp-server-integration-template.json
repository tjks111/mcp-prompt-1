{
  "id": "mcp-server-integration-template",
  "name": "MCP Server Integration Guide",
  "description": "A comprehensive template for planning, configuring, and integrating multiple MCP servers into a cohesive ecosystem",
  "content": "# MCP Server Integration Guide\n\nI'll help you integrate multiple MCP servers to create a powerful AI context ecosystem for {{project_name}}. By combining specialized MCP servers, you can significantly enhance AI capabilities beyond what a single model can provide.\n\n## Project Requirements Analysis\n\n### Core Use Case\n\nYour primary use case for MCP server integration is:\n- **{{primary_use_case}}**\n\n### Key Requirements\n\nBased on your use case, we'll focus on these requirements:\n1. {{requirement_1}}\n2. {{requirement_2}}\n3. {{requirement_3}}\n\n## MCP Server Selection\n\nBased on your requirements, I recommend these MCP servers:\n\n### Core Infrastructure\n- **{{primary_mcp_server}}**: {{primary_server_description}}\n- **{{secondary_mcp_server}}**: {{secondary_server_description}}\n- **{{tertiary_mcp_server}}**: {{tertiary_server_description}}\n\n### Supporting Services\n- Additional servers to consider: {{additional_servers}}\n\n## Integration Architecture\n\n```mermaid\ngraph TD\n    Client[AI Client] --> |Requests| Primary[{{primary_mcp_server}}]\n    Primary --> |Data Flow| Secondary[{{secondary_mcp_server}}]\n    Primary --> |Data Flow| Tertiary[{{tertiary_mcp_server}}]\n    \n    subgraph \"Core MCP Ecosystem\"\n        Primary\n        Secondary\n        Tertiary\n    end\n```\n\n## Configuration and Setup\n\n### Installation Steps\n\n1. **{{primary_mcp_server}}**:\n   ```bash\n   {{primary_installation_command}}\n   ```\n\n2. **{{secondary_mcp_server}}**:\n   ```bash\n   {{secondary_installation_command}}\n   ```\n\n3. **{{tertiary_mcp_server}}**:\n   ```bash\n   {{tertiary_installation_command}}\n   ```\n\n### Claude Desktop Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"{{primary_mcp_server_id}}\": {\n      \"command\": \"{{primary_command}}\",\n      \"args\": [{{primary_args}}],\n      \"env\": {\n        {{primary_env_vars}}\n      }\n    },\n    \"{{secondary_mcp_server_id}}\": {\n      \"command\": \"{{secondary_command}}\",\n      \"args\": [{{secondary_args}}],\n      \"env\": {\n        {{secondary_env_vars}}\n      }\n    },\n    \"{{tertiary_mcp_server_id}}\": {\n      \"command\": \"{{tertiary_command}}\",\n      \"args\": [{{tertiary_args}}],\n      \"env\": {\n        {{tertiary_env_vars}}\n      }\n    }\n  }\n}\n```\n\n### Docker Compose Integration\n\n```yaml\nversion: '3'\nservices:\n  {{primary_mcp_server_id}}:\n    image: {{primary_image}}\n    environment:\n      - {{primary_environment_1}}\n      - {{primary_environment_2}}\n    volumes:\n      - {{primary_volume_mapping}}\n    ports:\n      - \"{{primary_port_mapping}}\"\n      \n  {{secondary_mcp_server_id}}:\n    image: {{secondary_image}}\n    environment:\n      - {{secondary_environment_1}}\n      - {{secondary_environment_2}}\n    volumes:\n      - {{secondary_volume_mapping}}\n    ports:\n      - \"{{secondary_port_mapping}}\"\n      \n  {{tertiary_mcp_server_id}}:\n    image: {{tertiary_image}}\n    environment:\n      - {{tertiary_environment_1}}\n      - {{tertiary_environment_2}}\n    volumes:\n      - {{tertiary_volume_mapping}}\n    ports:\n      - \"{{tertiary_port_mapping}}\"\n```\n\n## Integration Patterns\n\n### Data Flow\n\nFor your use case, I recommend the following data flow pattern:\n\n```\n{{data_flow_pattern}}\n```\n\n### Communication Model\n\nThe optimal communication model for your servers is:\n**{{communication_model}}**\n\nRationale: {{communication_rationale}}\n\n## Best Practices for Your Integration\n\n1. **Performance Optimization**: {{performance_recommendation}}\n2. **Security Considerations**: {{security_recommendation}}\n3. **Error Handling**: {{error_handling_recommendation}}\n4. **Testing Strategy**: {{testing_recommendation}}\n\n## MCP Server Interaction Examples\n\n### Example 1: {{example_scenario_1}}\n\n```javascript\n// Client-side code example\nuse_mcp_tool({\n  server_name: \"{{primary_mcp_server_id}}\",\n  tool_name: \"{{example_tool_1}}\",\n  arguments: {\n    {{example_args_1}}\n  }\n});\n```\n\n### Example 2: {{example_scenario_2}}\n\n```javascript\n// Client-side code example\nuse_mcp_tool({\n  server_name: \"{{secondary_mcp_server_id}}\",\n  tool_name: \"{{example_tool_2}}\",\n  arguments: {\n    {{example_args_2}}\n  }\n});\n```\n\n## Troubleshooting Guide\n\n| Problem | Possible Cause | Solution |\n|---------|----------------|----------|\n| {{problem_1}} | {{cause_1}} | {{solution_1}} |\n| {{problem_2}} | {{cause_2}} | {{solution_2}} |\n| {{problem_3}} | {{cause_3}} | {{solution_3}} |\n\n## Next Steps\n\n1. {{next_step_1}}\n2. {{next_step_2}}\n3. {{next_step_3}}\n\nWould you like me to elaborate on any specific aspect of this MCP server integration plan?",
  "variables": [
    "project_name",
    "primary_use_case",
    "requirement_1",
    "requirement_2",
    "requirement_3",
    "primary_mcp_server",
    "primary_server_description",
    "secondary_mcp_server",
    "secondary_server_description",
    "tertiary_mcp_server",
    "tertiary_server_description",
    "additional_servers",
    "primary_installation_command",
    "secondary_installation_command",
    "tertiary_installation_command",
    "primary_mcp_server_id",
    "primary_command",
    "primary_args",
    "primary_env_vars",
    "secondary_mcp_server_id",
    "secondary_command",
    "secondary_args",
    "secondary_env_vars",
    "tertiary_mcp_server_id",
    "tertiary_command",
    "tertiary_args",
    "tertiary_env_vars",
    "primary_image",
    "primary_environment_1",
    "primary_environment_2",
    "primary_volume_mapping",
    "primary_port_mapping",
    "secondary_image",
    "secondary_environment_1",
    "secondary_environment_2",
    "secondary_volume_mapping",
    "secondary_port_mapping",
    "tertiary_image",
    "tertiary_environment_1",
    "tertiary_environment_2",
    "tertiary_volume_mapping",
    "tertiary_port_mapping",
    "data_flow_pattern",
    "communication_model",
    "communication_rationale",
    "performance_recommendation",
    "security_recommendation",
    "error_handling_recommendation",
    "testing_recommendation",
    "example_scenario_1",
    "example_tool_1",
    "example_args_1",
    "example_scenario_2",
    "example_tool_2",
    "example_args_2",
    "problem_1",
    "cause_1",
    "solution_1",
    "problem_2",
    "cause_2",
    "solution_2",
    "problem_3",
    "cause_3",
    "solution_3",
    "next_step_1",
    "next_step_2",
    "next_step_3"
  ],
  "examples": [
    {
      "name": "Development Environment Integration",
      "values": {
        "project_name": "AI-Enhanced Development Environment",
        "primary_use_case": "Creating an integrated development environment that enhances coding, documentation, and testing with AI assistance",
        "requirement_1": "Code repository analysis and exploration",
        "requirement_2": "Database query and schema analysis",
        "requirement_3": "Documentation generation and enhancement",
        "primary_mcp_server": "github",
        "primary_server_description": "Integrates with GitHub repositories to provide code context and exploration",
        "secondary_mcp_server": "filesystem",
        "secondary_server_description": "Provides access to local project files and configuration",
        "tertiary_mcp_server": "postgres",
        "tertiary_server_description": "Allows database exploration and SQL query execution",
        "additional_servers": "prompts, sequential-thinking, memory",
        "primary_installation_command": "npx -y @modelcontextprotocol/server-github",
        "secondary_installation_command": "npx -y @modelcontextprotocol/server-filesystem /path/to/workspace",
        "tertiary_installation_command": "npx -y @modelcontextprotocol/server-postgres postgresql://localhost/mydb",
        "primary_mcp_server_id": "github",
        "primary_command": "npx",
        "primary_args": "\"-y\", \"@modelcontextprotocol/server-github\"",
        "primary_env_vars": "\"GITHUB_PERSONAL_ACCESS_TOKEN\": \"your-token-here\"",
        "secondary_mcp_server_id": "filesystem",
        "secondary_command": "npx",
        "secondary_args": "\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/workspace\"",
        "secondary_env_vars": "",
        "tertiary_mcp_server_id": "postgres",
        "tertiary_command": "npx",
        "tertiary_args": "\"-y\", \"@modelcontextprotocol/server-postgres\", \"postgresql://localhost/mydb\"",
        "tertiary_env_vars": "",
        "primary_image": "node:alpine",
        "primary_environment_1": "GITHUB_PERSONAL_ACCESS_TOKEN=your-token-here",
        "primary_environment_2": "PORT=3001",
        "primary_volume_mapping": "./data:/data",
        "primary_port_mapping": "3001:3000",
        "secondary_image": "node:alpine",
        "secondary_environment_1": "PORT=3002",
        "secondary_environment_2": "",
        "secondary_volume_mapping": "./workspace:/workspace",
        "secondary_port_mapping": "3002:3000",
        "tertiary_image": "node:alpine",
        "tertiary_environment_1": "PORT=3003",
        "tertiary_environment_2": "",
        "tertiary_volume_mapping": "./pgdata:/var/lib/postgresql/data",
        "tertiary_port_mapping": "3003:3000",
        "data_flow_pattern": "GitHub → Filesystem → Postgres → Client, with bidirectional flows as needed",
        "communication_model": "Hub and Spoke with GitHub as the central hub",
        "communication_rationale": "Centralizing around GitHub allows for repository-centric workflows, which matches most development scenarios",
        "performance_recommendation": "Use volume mounting for filesystem paths to minimize container rebuild times during development",
        "security_recommendation": "Utilize environment variables and Docker secrets for sensitive tokens and credentials",
        "error_handling_recommendation": "Implement retries with exponential backoff for GitHub API requests to handle rate limiting",
        "testing_recommendation": "Create a test suite with mock repositories to validate cross-server integration before production use",
        "example_scenario_1": "Exploring a repository",
        "example_tool_1": "list_repositories",
        "example_args_1": "owner: \"username\", limit: 5",
        "example_scenario_2": "Reading project files",
        "example_tool_2": "read_directory",
        "example_args_2": "path: \"/workspace/src\"",
        "problem_1": "GitHub API rate limiting",
        "cause_1": "Too many requests in a short time period",
        "solution_1": "Implement caching and rate limiting in the client code",
        "problem_2": "Permission denied for filesystem",
        "cause_2": "Container user doesn't have access to mounted volumes",
        "solution_2": "Check file permissions and user IDs in container",
        "problem_3": "Database connection issues",
        "cause_3": "Incorrect connection string or database not running",
        "solution_3": "Verify database is running and connection parameters are correct",
        "next_step_1": "Set up Docker Compose environment with the three core MCP servers",
        "next_step_2": "Configure Claude Desktop to use these MCP servers",
        "next_step_3": "Create sample prompts that utilize multiple servers for code exploration tasks"
      }
    },
    {
      "name": "Content Creation Ecosystem",
      "values": {
        "project_name": "AI-Powered Content Creation Suite",
        "primary_use_case": "Building a sophisticated content creation system with research, drafting, and media generation capabilities",
        "requirement_1": "Real-time web research and citation gathering",
        "requirement_2": "Automated content generation with template support",
        "requirement_3": "Text-to-speech conversion for audio content",
        "primary_mcp_server": "brave-search",
        "primary_server_description": "Provides up-to-date web search capabilities for research",
        "secondary_mcp_server": "prompts",
        "secondary_server_description": "Manages content templates and generation patterns",
        "tertiary_mcp_server": "elevenlabs",
        "tertiary_server_description": "Converts text to high-quality speech for podcasts or audio content",
        "additional_servers": "memory, filesystem",
        "primary_installation_command": "npx -y @modelcontextprotocol/server-brave-search",
        "secondary_installation_command": "npx -y @sparesparrow/mcp-prompts",
        "tertiary_installation_command": "uvx elevenlabs-mcp-server",
        "primary_mcp_server_id": "brave-search",
        "primary_command": "npx",
        "primary_args": "\"-y\", \"@modelcontextprotocol/server-brave-search\"",
        "primary_env_vars": "\"BRAVE_API_KEY\": \"your-brave-api-key\"",
        "secondary_mcp_server_id": "prompts",
        "secondary_command": "npx",
        "secondary_args": "\"-y\", \"@sparesparrow/mcp-prompts\"",
        "secondary_env_vars": "\"STORAGE_TYPE\": \"file\", \"PROMPTS_DIR\": \"/path/to/prompts\"",
        "tertiary_mcp_server_id": "elevenlabs",
        "tertiary_command": "uvx",
        "tertiary_args": "\"elevenlabs-mcp-server\"",
        "tertiary_env_vars": "\"ELEVENLABS_API_KEY\": \"your-elevenlabs-api-key\", \"ELEVENLABS_VOICE_ID\": \"preferred-voice-id\"",
        "primary_image": "node:alpine",
        "primary_environment_1": "BRAVE_API_KEY=your-brave-api-key",
        "primary_environment_2": "PORT=3001",
        "primary_volume_mapping": "./data:/data",
        "primary_port_mapping": "3001:3000",
        "secondary_image": "sparesparrow/mcp-prompts:latest",
        "secondary_environment_1": "STORAGE_TYPE=file",
        "secondary_environment_2": "PROMPTS_DIR=/app/data/prompts",
        "secondary_volume_mapping": "./prompts:/app/data/prompts",
        "secondary_port_mapping": "3002:3000",
        "tertiary_image": "node:alpine",
        "tertiary_environment_1": "ELEVENLABS_API_KEY=your-elevenlabs-api-key",
        "tertiary_environment_2": "ELEVENLABS_VOICE_ID=preferred-voice-id",
        "tertiary_volume_mapping": "./audio:/app/data/audio",
        "tertiary_port_mapping": "3003:3000",
        "data_flow_pattern": "Brave Search → Prompts → ElevenLabs → Client, with the option to store results in Memory or Filesystem",
        "communication_model": "Pipeline Processing",
        "communication_rationale": "Content creation naturally follows a linear workflow from research to drafting to audio production",
        "performance_recommendation": "Cache search results from Brave Search to minimize API usage and improve response times",
        "security_recommendation": "Store all API keys in environment variables and never expose them in generated content",
        "error_handling_recommendation": "Implement fallback voices for ElevenLabs in case the primary voice is unavailable",
        "testing_recommendation": "Create sample prompts that exercise the full pipeline from research to audio generation",
        "example_scenario_1": "Researching a topic",
        "example_tool_1": "search",
        "example_args_1": "query: \"latest developments in AI assistants 2025\"",
        "example_scenario_2": "Generating an article template",
        "example_tool_2": "apply_template",
        "example_args_2": "template_id: \"blog-article\", variables: {topic: \"AI advancements\", tone: \"educational\"}",
        "problem_1": "Brave Search API limits exceeded",
        "cause_1": "Too many searches in a short time period",
        "solution_1": "Implement rate limiting and caching for search results",
        "problem_2": "Missing prompts or templates",
        "cause_2": "Incorrect path to prompts directory",
        "solution_2": "Verify PROMPTS_DIR environment variable points to existing directory",
        "problem_3": "ElevenLabs audio generation fails",
        "cause_3": "Invalid API key or voice ID",
        "solution_3": "Check API key validity and available voices through ElevenLabs dashboard",
        "next_step_1": "Set up Docker Compose environment with all three MCP servers",
        "next_step_2": "Create a set of content templates in the prompts server",
        "next_step_3": "Develop a sample workflow that demonstrates research, content generation, and audio production"
      }
    }
  ],
  "categories": ["integration", "multi-server", "configuration", "advanced", "docker"]
} 